{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SESSION_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will use the same env curso_1 from session_1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites: **In a terminal**, You need to create, install biopython and activate the `Conda` env as follow before to start jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!conda install -y -n curso_1 -c bioconda seqtk minimap2 nanoq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!conda activate curso_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!jupyter notebook &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data [bs_reads.fastq.gz](https://filesender.renater.fr/?s=download&token=475acb28-fcd4-4986-ab82-84733a1f7f5f) before and put the file in the **Session_2/data/bacillus_subtilis** directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality control of fastq reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many bases have been sequenced and basecalled ? Use seqtk.  \n",
    "[Seqtk](https://github.com/lh3/seqtk) is a fast and lightweight tool for processing sequences in the FASTA or FASTQ format. It seamlessly parses both FASTA and FASTQ files which can also be optionally compressed by gzip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 178259749\r\n"
     ]
    }
   ],
   "source": [
    "!seqtk seq -A data/bacillus_subtilis/bs_reads.fastq.gz | grep -v \">\" |wc -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Quality Control of FASTQ with [nanoq](https://www.theoj.org/joss-papers/joss.02991/10.21105.joss.02991.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nanoq 0.9.0\r\n",
      "Read filters and summary reports for nanopore data\r\n",
      "\r\n",
      "USAGE:\r\n",
      "    nanoq [FLAGS] [OPTIONS]\r\n",
      "\r\n",
      "FLAGS:\r\n",
      "    -f, --fast       Ignore quality values if present\r\n",
      "    -h, --help       Prints help information\r\n",
      "    -H, --header     Header for summary output\r\n",
      "    -j, --json       Summary report in JSON format\r\n",
      "    -s, --stats      Summary report only [stdout]\r\n",
      "    -V, --version    Prints version information\r\n",
      "    -v, --verbose    Verbose output statistics [multiple, up to -vvv]\r\n",
      "\r\n",
      "OPTIONS:\r\n",
      "    -c, --compress-level <1-9>     Compression level to use if compressing output [default: 6]\r\n",
      "    -i, --input <input>            Fast{a,q}.{gz,xz,bz}, stdin if not present\r\n",
      "    -m, --max-len <INT>            Maximum read length filter (bp) [default: 0]\r\n",
      "    -w, --max-qual <FLOAT>         Maximum average read quality filter (Q) [default: 0]\r\n",
      "    -l, --min-len <INT>            Minimum read length filter (bp) [default: 0]\r\n",
      "    -q, --min-qual <FLOAT>         Minimum average read quality filter (Q) [default: 0]\r\n",
      "    -o, --output <output>          Output filepath, stdout if not present\r\n",
      "    -O, --output-type <u|b|g|l>    u: uncompressed; b: Bzip2; g: Gzip; l: Lzma\r\n",
      "    -r, --report <report>          Summary report output file\r\n",
      "    -t, --top <INT>                Number of top reads in verbose summary [default: 5]\r\n"
     ]
    }
   ],
   "source": [
    "!nanoq -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nanoq -i data/bacillus_subtilis/bs_reads.fastq.gz -r out_nanoq.txt -s -H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat out_nanoq.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality control can also be done by [fastqc](https://timkahlke.github.io/LongRead_tutorials/QC_F.html)  \n",
    "**Don't do it, Very slow !**  \n",
    "But I did it for you -> **[HERE](http://localhost:8888/view/Documents/GitHub/Botucatu_Course_March_2024/Session_2/bs_reads_fastqc.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality Control of FASTQ with [Nanoplot](https://github.com/wdecoster/NanoPlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Nanoplot using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nanoplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!NanoPlot --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use NanoPlot to ckeck quality of reads (See report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!NanoPlot -t 1 --fastq data/bacillus_subtilis/bs_reads.fastq --outdir NANOPLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other usefull tools (in https://github.com/wdecoster/NanoPlot).  \n",
    "`NanoComp`: comparing multiple runs.  \n",
    "`NanoStat`: statistic summary report of reads or alignments.    \n",
    "`NanoFilt`: filtering and trimming of reads.  \n",
    "`NanoLyse`: removing contaminant reads.  \n",
    "[`FiltLong`](https://github.com/rrwick/Filtlong): filtering long reads by quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPING READS AGAINST A REFERENCE USING MINIMAP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation of [`minimap2`](https://github.com/lh3/minimap2/) with conda before to run Jupyter notebook.  \n",
    "We have prepared a bigger Bacillus subtilis dataset that was basecalled beforehand. We will try to assemble the sequenced genome. But let's try to use `minimap2` to map fastq reads against the reference to handle files. \n",
    "At the next session we will use `minimap2` as the first step of an assembly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What to do with Minimap2 ?**\n",
    "\n",
    "-Map long noisy genomic reads.  \n",
    "-Map long mRNA/cDNA reads.  \n",
    "-Find overlaps between long reads.  \n",
    "-Map short accurate genomic reads.  \n",
    "-Full genome/assembly alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: minimap2 [options] <target.fa>|<target.idx> [query.fa] [...]\r\n",
      "Options:\r\n",
      "  Indexing:\r\n",
      "    -H           use homopolymer-compressed k-mer (preferrable for PacBio)\r\n",
      "    -k INT       k-mer size (no larger than 28) [15]\r\n",
      "    -w INT       minimizer window size [10]\r\n",
      "    -I NUM       split index for every ~NUM input bases [4G]\r\n",
      "    -d FILE      dump index to FILE []\r\n",
      "  Mapping:\r\n",
      "    -f FLOAT     filter out top FLOAT fraction of repetitive minimizers [0.0002]\r\n",
      "    -g NUM       stop chain enlongation if there are no minimizers in INT-bp [5000]\r\n",
      "    -G NUM       max intron length (effective with -xsplice; changing -r) [200k]\r\n",
      "    -F NUM       max fragment length (effective with -xsr or in the fragment mode) [800]\r\n",
      "    -r NUM[,NUM] chaining/alignment bandwidth and long-join bandwidth [500,20000]\r\n",
      "    -n INT       minimal number of minimizers on a chain [3]\r\n",
      "    -m INT       minimal chaining score (matching bases minus log gap penalty) [40]\r\n",
      "    -X           skip self and dual mappings (for the all-vs-all mode)\r\n",
      "    -p FLOAT     min secondary-to-primary score ratio [0.8]\r\n",
      "    -N INT       retain at most INT secondary alignments [5]\r\n",
      "  Alignment:\r\n",
      "    -A INT       matching score [2]\r\n",
      "    -B INT       mismatch penalty (larger value for lower divergence) [4]\r\n",
      "    -O INT[,INT] gap open penalty [4,24]\r\n",
      "    -E INT[,INT] gap extension penalty; a k-long gap costs min{O1+k*E1,O2+k*E2} [2,1]\r\n",
      "    -z INT[,INT] Z-drop score and inversion Z-drop score [400,200]\r\n",
      "    -s INT       minimal peak DP alignment score [80]\r\n",
      "    -u CHAR      how to find GT-AG. f:transcript strand, b:both strands, n:don't match GT-AG [n]\r\n",
      "  Input/Output:\r\n",
      "    -a           output in the SAM format (PAF by default)\r\n",
      "    -o FILE      output alignments to FILE [stdout]\r\n",
      "    -L           write CIGAR with >65535 ops at the CG tag\r\n",
      "    -R STR       SAM read group line in a format like '@RG\\tID:foo\\tSM:bar' []\r\n",
      "    -c           output CIGAR in PAF\r\n",
      "    --cs[=STR]   output the cs tag; STR is 'short' (if absent) or 'long' [none]\r\n",
      "    --MD         output the MD tag\r\n",
      "    --eqx        write =/X CIGAR operators\r\n",
      "    -Y           use soft clipping for supplementary alignments\r\n",
      "    -t INT       number of threads [3]\r\n",
      "    -K NUM       minibatch size for mapping [500M]\r\n",
      "    --version    show version number\r\n",
      "  Preset:\r\n",
      "    -x STR       preset (always applied before other options; see minimap2.1 for details) []\r\n",
      "                 - map-pb/map-ont - PacBio CLR/Nanopore vs reference mapping\r\n",
      "                 - map-hifi - PacBio HiFi reads vs reference mapping\r\n",
      "                 - ava-pb/ava-ont - PacBio/Nanopore read overlap\r\n",
      "                 - asm5/asm10/asm20 - asm-to-ref mapping, for ~0.1/1/5% sequence divergence\r\n",
      "                 - splice/splice:hq - long-read/Pacbio-CCS spliced alignment\r\n",
      "                 - sr - genomic short-read mapping\r\n",
      "\r\n",
      "See `man ./minimap2.1' for detailed description of these and other advanced command-line options.\r\n"
     ]
    }
   ],
   "source": [
    "!minimap2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go ahead and map all our reads to the reference genome without looking for alignments at this point. There are several reasons why we would to this and one of them is to check how many reads are mappable to the reference, and calculate the average base coverage of the sequencing run by choosing the best overlap for each read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!minimap2 \\\n",
    "    -x map-ont \\\n",
    "    -o bs_reads_to_ref.paf \\\n",
    "    data/bacillus_subtilis/bs_ref.fasta data/bacillus_subtilis/bs_reads.fastq.gz\n",
    "\n",
    "#-x map-ont; for Oxford Nanopore reads "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results is in [PAF (Pairwise mApping Format) format](https://github.com/lh3/miniasm/blob/master/PAF.md).  \n",
    "\n",
    "See below the tabular format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Col|Type|Description  |\n",
    "|---|---|---|\n",
    "|1|string|Query sequence name  |\n",
    "|2|int|Query sequence length  |\n",
    "|3|int|Query start (0-based; BED-like; closed) | \n",
    "|4|int|Query end (0-based; BED-like; open)  |\n",
    "|5|char|Relative strand: \"+\" or \"-\"  |\n",
    "|6|string|Target sequence name  |\n",
    "|7|int|Target sequence length  |\n",
    "|8|int|Target start on original strand (0-based)  |\n",
    "|9|int|Target end on original strand (0-based)  |\n",
    "|10|int|Number of residue matches  |\n",
    "|11|int|Alignment block length  |\n",
    "|12|int|Mapping quality (0-255; 255 for missing)  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat bs_reads_to_ref.paf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "paf = pandas.read_csv('bs_reads_to_ref.paf', header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -k data/bacillus_subtilis/bs_reads.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "reads = []\n",
    "with open('data/bacillus_subtilis/bs_reads.fastq') as handle:\n",
    "    for read in SeqIO.parse(handle, 'fastq'):\n",
    "        reads.append(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Num seq        =\", len(reads))\n",
    "print(\"Num mapped seq =\", len(paf[0].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paf[paf.duplicated(subset = 0, keep = 'first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paf.drop_duplicates(subset = 0, keep = 'first', inplace = True)\n",
    "paf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import seaborn\n",
    "\n",
    "reflen = paf[6][0]\n",
    "\n",
    "b = [0] * reflen\n",
    "e = [0] * reflen\n",
    "for i, row in paf.iterrows():\n",
    "    b[row[7]] += 1\n",
    "    e[row[8]] += 1\n",
    "\n",
    "pile = [0] * reflen\n",
    "coverage = 0\n",
    "for i in range(reflen):\n",
    "    coverage += b[i]\n",
    "    pile[i] += coverage\n",
    "    coverage -= e[i]\n",
    "\n",
    "print(\"Avg base coverage =\", sum(pile) / reflen)\n",
    "_ = pyplot.plot(pile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pyplot.plot(pile[500000:1000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Minimap` can also find alignments which we will use to calculate the average accuracy of our data. \n",
    "This can be done by passing parameter `-a` which will print the output in SAM format, but we can also use `-c` to let minimap2 put the CIGAR string in the last column of the PAF file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same thing does ratlesnake, it uses minimizers and the minimap algorithm to find best positions of each read in the reference, and then calculates edit distance with edlib (instead of ksw2 in minimap2). To get the accuracy histogram, we run ratlesnake as in session 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!minimap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!minimap2 \\\n",
    "    -x map-ont \\\n",
    "    -c \\\n",
    "    --eqx \\\n",
    "    -o bs_reads_to_ref.cigar.paf \\\n",
    "    data/bacillus_subtilis/bs_ref.fasta \\\n",
    "    data/bacillus_subtilis/bs_reads.fastq.gz\n",
    "#-c output CIGAR in PAF\n",
    "#--eqx write =/X CIGAR operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install **again** Ratlesnake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/lbcb-sci/ratlesnake\n",
    "!mkdir ratlesnake/build\n",
    "!cmake -S ratlesnake -B ratlesnake/build -DCMAKE_BUILD_TYPE=Release\n",
    "!make -C ratlesnake/build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ratlesnake/build/bin/ratlesnake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ratlesnake/build/bin/ratlesnake \\\n",
    "    -r 1 \\\n",
    "    -t 4 \\\n",
    "    data/bacillus_subtilis/bs_reads.fastq.gz \\\n",
    "    data/bacillus_subtilis/bs_ref.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Advanced users/players only :**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paf = pandas.read_csv('bs_reads_to_ref.cigar.paf', header = None, delimiter = '\\t', error_bad_lines = False)\n",
    "paf.drop_duplicates(subset = 0, keep = 'first', inplace = True)\n",
    "paf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_accuracy(paf):\n",
    "    stats = {'=': [], 'X': [], 'I': [], 'D': []}\n",
    "    for i, row in paf.iterrows():\n",
    "        if pandas.isnull(row[22]):\n",
    "            continue\n",
    "        read = {'=': 0., 'X': 0., 'I': 0., 'D': 0.}\n",
    "        cigar = row[22][5:]\n",
    "        n = ''\n",
    "        for c in cigar:\n",
    "            if c in ['=', 'X', 'I', 'D']:\n",
    "                read[c] += int(n)\n",
    "                n = ''\n",
    "            else:\n",
    "                n += c\n",
    "        for m, n in read.items():\n",
    "            stats[m].append(n / sum(read.values()))\n",
    "\n",
    "    return stats\n",
    "\n",
    "stats = base_accuracy(paf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def print_statistics(stats):\n",
    "    print('  Min      Median   Mean     Max')\n",
    "    for m, n in stats.items():\n",
    "        print(m, '{0:.6f}'.format(min(n)), '{0:.6f}'.format(statistics.median(n)), '{0:.6f}'.format(statistics.mean(n)), '{0:.6f}'.format(max(n)))\n",
    "\n",
    "print_statistics(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
